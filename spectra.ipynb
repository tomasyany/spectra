{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPECTRA\n",
    "### SPectrum Evidence Classifier Terrific Royal Application\n",
    "\n",
    "Welcome to SPECTRA, the mini application for the analysis and classification of galaxies' spectra.\n",
    "Lets start by installing all the packages from `requirements.txt`.\n",
    "\n",
    "Run the following code in your shell, while on a virtual environment:  \n",
    "`>>> pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st method: Dynamic Time Warping (DTW) + K-Nearest Neighbours (KNN)\n",
    "The steps for this first approach are as follow:\n",
    "1. Slice all the spectra to erase noise in red zones\n",
    "2. Compute DTW distance between every pair of spectra\n",
    "3. Use KNN algorithm with known classes from training set to define the classes of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomasyany/Code/envs/memoria/lib/python3.4/site-packages/IPython/kernel/__init__.py:13: ShimWarning: The `IPython.kernel` package has been deprecated. You should import from ipykernel or jupyter_client instead.\n",
      "  \"You should import from ipykernel or jupyter_client instead.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "from premanager.dtw import DTW\n",
    "\n",
    "from premanager.listing import Listing\n",
    "from premanager.extractor import Extractor\n",
    "from tabulate import tabulate\n",
    "\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A small example of the computation of the DTW versus Euclidean (for PASSIVE galaxies)\n",
    "\n",
    "test_files = Listing.get_random_files('PASSIVE', 2)\n",
    "\n",
    "lcp, rcp = 0, 9200\n",
    "\n",
    "all_times = []\n",
    "distances = []\n",
    "\n",
    "for index1, sp1 in enumerate(test_files):\n",
    "    sp1_name = \"Spec\"+str(index1)\n",
    "    \n",
    "    fits_file1 = Extractor.open_fits_file(sp1)\n",
    "    obs, sp1_values = Extractor.get_obs_values(sp1, fits_file1, lcp, rcp)\n",
    "    sp1_values = array(sp1_values)\n",
    "    \n",
    "    for index2, sp2 in enumerate(test_files):\n",
    "        sp2_name = \"Spec\"+str(index2)\n",
    "        fits_file2 = Extractor.open_fits_file(sp2)\n",
    "        obs, sp2_values = Extractor.get_obs_values(sp1, fits_file2, lcp, rcp)\n",
    "        sp2_values = array(sp2_values)\n",
    "        \n",
    "        if sp1 != sp2:\n",
    "            start = time()\n",
    "            my_dtw = DTW(sp1_values, sp2_values)\n",
    "            \n",
    "            my_cost_matrix = my_dtw.compute_cost_matrix(DTW.euclidean_distance)\n",
    "            my_acc_matrix, cost = my_dtw.compute_acc_cost_matrix(my_cost_matrix)\n",
    "            \n",
    "            dtw_sp = cost\n",
    "            \n",
    "            end = time()\n",
    "            all_times.append([(sp1_name, sp2_name), round(end-start, 1)])\n",
    "\n",
    "            s = 800\n",
    "            \n",
    "            euc_sp = DTW.euclidean_distance(sp1_values[:s], sp2_values[:s])/(len(sp1_values[:s])+len(sp2_values[:s]))\n",
    "            \n",
    "            distances.append([(sp1_name, sp2_name), dtw_sp, euc_sp])\n",
    "        Extractor.close_fits_file(fits_file2)\n",
    "        \n",
    "    Extractor.close_fits_file(fits_file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print results for distances and computation times\n",
    "\n",
    "all_times_pa = all_times\n",
    "distances_pa = distances\n",
    "print(tabulate(all_times_pa, tablefmt='latex'))\n",
    "print(tabulate(distances_pa, tablefmt='latex'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A small example of the computation of the DTW versus Euclidean (for STARBURST galaxies)\n",
    "\n",
    "test_files = Listing.get_random_files('STARBURST', 5)\n",
    "\n",
    "lcp, rcp = 0, 9200\n",
    "\n",
    "all_times = []\n",
    "distances = []\n",
    "\n",
    "for index1, sp1 in enumerate(test_files):\n",
    "    sp1_name = \"Spec\"+str(index1)\n",
    "    \n",
    "    fits_file1 = Extractor.open_fits_file(sp1)\n",
    "    obs, sp1_values = Extractor.get_obs_values(sp1, fits_file1, lcp, rcp)\n",
    "    sp1_values = array(sp1_values)\n",
    "    \n",
    "    for index2, sp2 in enumerate(test_files):\n",
    "        sp2_name = \"Spec\"+str(index2)\n",
    "        fits_file2 = Extractor.open_fits_file(sp2)\n",
    "        obs, sp2_values = Extractor.get_obs_values(sp1, fits_file2, lcp, rcp)\n",
    "        sp2_values = array(sp2_values)\n",
    "        \n",
    "        if sp1 != sp2:\n",
    "            start = time()\n",
    "            my_dtw = DTW(sp1_values, sp2_values)\n",
    "            \n",
    "            my_cost_matrix = my_dtw.compute_cost_matrix(DTW.euclidean_distance)\n",
    "            my_acc_matrix, cost = my_dtw.compute_acc_cost_matrix(my_cost_matrix)\n",
    "            \n",
    "            dtw_sp = cost\n",
    "            \n",
    "            end = time()\n",
    "            all_times.append([(sp1_name, sp2_name), round(end-start, 1)])\n",
    "\n",
    "            s = 800\n",
    "            \n",
    "            euc_sp = DTW.euclidean_distance(sp1_values[:s], sp2_values[:s])\n",
    "            \n",
    "            distances.append([(sp1_name, sp2_name), dtw_sp, euc_sp])\n",
    "        Extractor.close_fits_file(fits_file2)\n",
    "        \n",
    "    Extractor.close_fits_file(fits_file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print results for distances and computation times\n",
    "\n",
    "all_times_st = all_times\n",
    "distances_st = distances\n",
    "print(tabulate(all_times_st, tablefmt='latex'))\n",
    "print(tabulate(distances_st, tablefmt='latex'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A small example of the computation of the DTW versus Euclidean (for 2 random galaxies of each class)\n",
    "\n",
    "test_files = Listing.get_random_galaxies(2)\n",
    "\n",
    "lcp, rcp = 0, 9200\n",
    "\n",
    "all_times = []\n",
    "distances = []\n",
    "\n",
    "for index1, sp1 in enumerate(test_files):\n",
    "    sp1_name = \"Spec\"+str(index1)+'('+sp1.split('/')[1]+')'\n",
    "    \n",
    "    fits_file1 = Extractor.open_fits_file(sp1)\n",
    "    obs, sp1_values = Extractor.get_obs_values(sp1, fits_file1, lcp, rcp)\n",
    "    sp1_values = array(sp1_values)\n",
    "    \n",
    "    for index2, sp2 in enumerate(test_files):\n",
    "        sp2_name = \"Spec\"+str(index2)+'('+sp2.split('/')[1]+')'\n",
    "        fits_file2 = Extractor.open_fits_file(sp2)\n",
    "        obs, sp2_values = Extractor.get_obs_values(sp1, fits_file2, lcp, rcp)\n",
    "        sp2_values = array(sp2_values)\n",
    "        \n",
    "        if sp1 != sp2:\n",
    "            start = time()\n",
    "            my_dtw = DTW(sp1_values, sp2_values)\n",
    "            \n",
    "            my_cost_matrix = my_dtw.compute_cost_matrix(DTW.euclidean_distance)\n",
    "            my_acc_matrix, cost = my_dtw.compute_acc_cost_matrix(my_cost_matrix)\n",
    "            \n",
    "            dtw_sp = cost\n",
    "            \n",
    "            end = time()\n",
    "            all_times.append([(sp1_name, sp2_name), round(end-start, 1)])\n",
    "\n",
    "            s = 800\n",
    "            \n",
    "            euc_sp = DTW.euclidean_distance(sp1_values[:s], sp2_values[:s])/(len(sp1_values[:s])+len(sp2_values[:s]))\n",
    "            \n",
    "            distances.append([(sp1_name, sp2_name), dtw_sp, euc_sp])\n",
    "        Extractor.close_fits_file(fits_file2)\n",
    "        \n",
    "    Extractor.close_fits_file(fits_file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n",
      "\\begin{tabular}{lr}\n",
      "\\hline\n",
      " ('Spec0(PASSIVE)', 'Spec1(PASSIVE)')     & 14.2 \\\\\n",
      " ('Spec0(PASSIVE)', 'Spec2(POST)')        & 14.2 \\\\\n",
      " ('Spec0(PASSIVE)', 'Spec3(POST)')        & 14.1 \\\\\n",
      " ('Spec0(PASSIVE)', 'Spec4(QUIESCENT)')   & 14.4 \\\\\n",
      " ('Spec0(PASSIVE)', 'Spec5(QUIESCENT)')   & 14.4 \\\\\n",
      " ('Spec0(PASSIVE)', 'Spec6(DUSTY)')       & 14.4 \\\\\n",
      " ('Spec0(PASSIVE)', 'Spec7(DUSTY)')       & 14.4 \\\\\n",
      " ('Spec0(PASSIVE)', 'Spec8(STARBURST)')   & 14.2 \\\\\n",
      " ('Spec0(PASSIVE)', 'Spec9(STARBURST)')   & 14.4 \\\\\n",
      " ('Spec1(PASSIVE)', 'Spec0(PASSIVE)')     & 14.1 \\\\\n",
      " ('Spec1(PASSIVE)', 'Spec2(POST)')        & 14.4 \\\\\n",
      " ('Spec1(PASSIVE)', 'Spec3(POST)')        & 16.4 \\\\\n",
      " ('Spec1(PASSIVE)', 'Spec4(QUIESCENT)')   & 17.5 \\\\\n",
      " ('Spec1(PASSIVE)', 'Spec5(QUIESCENT)')   & 15.7 \\\\\n",
      " ('Spec1(PASSIVE)', 'Spec6(DUSTY)')       & 14.5 \\\\\n",
      " ('Spec1(PASSIVE)', 'Spec7(DUSTY)')       & 14.4 \\\\\n",
      " ('Spec1(PASSIVE)', 'Spec8(STARBURST)')   & 14.8 \\\\\n",
      " ('Spec1(PASSIVE)', 'Spec9(STARBURST)')   & 15.9 \\\\\n",
      " ('Spec2(POST)', 'Spec0(PASSIVE)')        & 22.4 \\\\\n",
      " ('Spec2(POST)', 'Spec1(PASSIVE)')        & 15.1 \\\\\n",
      " ('Spec2(POST)', 'Spec3(POST)')           & 14.2 \\\\\n",
      " ('Spec2(POST)', 'Spec4(QUIESCENT)')      & 16.9 \\\\\n",
      " ('Spec2(POST)', 'Spec5(QUIESCENT)')      & 15.1 \\\\\n",
      " ('Spec2(POST)', 'Spec6(DUSTY)')          & 15   \\\\\n",
      " ('Spec2(POST)', 'Spec7(DUSTY)')          & 14.9 \\\\\n",
      " ('Spec2(POST)', 'Spec8(STARBURST)')      & 16   \\\\\n",
      " ('Spec2(POST)', 'Spec9(STARBURST)')      & 15.2 \\\\\n",
      " ('Spec3(POST)', 'Spec0(PASSIVE)')        & 15   \\\\\n",
      " ('Spec3(POST)', 'Spec1(PASSIVE)')        & 14.6 \\\\\n",
      " ('Spec3(POST)', 'Spec2(POST)')           & 14.2 \\\\\n",
      " ('Spec3(POST)', 'Spec4(QUIESCENT)')      & 13.5 \\\\\n",
      " ('Spec3(POST)', 'Spec5(QUIESCENT)')      & 14.3 \\\\\n",
      " ('Spec3(POST)', 'Spec6(DUSTY)')          & 33.6 \\\\\n",
      " ('Spec3(POST)', 'Spec7(DUSTY)')          & 14.3 \\\\\n",
      " ('Spec3(POST)', 'Spec8(STARBURST)')      & 14.7 \\\\\n",
      " ('Spec3(POST)', 'Spec9(STARBURST)')      & 14.8 \\\\\n",
      " ('Spec4(QUIESCENT)', 'Spec0(PASSIVE)')   & 15.6 \\\\\n",
      " ('Spec4(QUIESCENT)', 'Spec1(PASSIVE)')   & 15.1 \\\\\n",
      " ('Spec4(QUIESCENT)', 'Spec2(POST)')      & 16   \\\\\n",
      " ('Spec4(QUIESCENT)', 'Spec3(POST)')      & 15.6 \\\\\n",
      " ('Spec4(QUIESCENT)', 'Spec5(QUIESCENT)') & 13.8 \\\\\n",
      " ('Spec4(QUIESCENT)', 'Spec6(DUSTY)')     & 13.7 \\\\\n",
      " ('Spec4(QUIESCENT)', 'Spec7(DUSTY)')     & 13.5 \\\\\n",
      " ('Spec4(QUIESCENT)', 'Spec8(STARBURST)') & 13.6 \\\\\n",
      " ('Spec4(QUIESCENT)', 'Spec9(STARBURST)') & 13.2 \\\\\n",
      " ('Spec5(QUIESCENT)', 'Spec0(PASSIVE)')   & 12.8 \\\\\n",
      " ('Spec5(QUIESCENT)', 'Spec1(PASSIVE)')   & 12.6 \\\\\n",
      " ('Spec5(QUIESCENT)', 'Spec2(POST)')      & 12.6 \\\\\n",
      " ('Spec5(QUIESCENT)', 'Spec3(POST)')      & 12.7 \\\\\n",
      " ('Spec5(QUIESCENT)', 'Spec4(QUIESCENT)') & 12.9 \\\\\n",
      " ('Spec5(QUIESCENT)', 'Spec6(DUSTY)')     & 12.9 \\\\\n",
      " ('Spec5(QUIESCENT)', 'Spec7(DUSTY)')     & 12.6 \\\\\n",
      " ('Spec5(QUIESCENT)', 'Spec8(STARBURST)') & 12.8 \\\\\n",
      " ('Spec5(QUIESCENT)', 'Spec9(STARBURST)') & 12.6 \\\\\n",
      " ('Spec6(DUSTY)', 'Spec0(PASSIVE)')       & 12.7 \\\\\n",
      " ('Spec6(DUSTY)', 'Spec1(PASSIVE)')       & 12.8 \\\\\n",
      " ('Spec6(DUSTY)', 'Spec2(POST)')          & 12.7 \\\\\n",
      " ('Spec6(DUSTY)', 'Spec3(POST)')          & 12.7 \\\\\n",
      " ('Spec6(DUSTY)', 'Spec4(QUIESCENT)')     & 12.7 \\\\\n",
      " ('Spec6(DUSTY)', 'Spec5(QUIESCENT)')     & 12.6 \\\\\n",
      " ('Spec6(DUSTY)', 'Spec7(DUSTY)')         & 12.6 \\\\\n",
      " ('Spec6(DUSTY)', 'Spec8(STARBURST)')     & 12.7 \\\\\n",
      " ('Spec6(DUSTY)', 'Spec9(STARBURST)')     & 12.6 \\\\\n",
      " ('Spec7(DUSTY)', 'Spec0(PASSIVE)')       & 12.8 \\\\\n",
      " ('Spec7(DUSTY)', 'Spec1(PASSIVE)')       & 12.5 \\\\\n",
      " ('Spec7(DUSTY)', 'Spec2(POST)')          & 12.6 \\\\\n",
      " ('Spec7(DUSTY)', 'Spec3(POST)')          & 12.5 \\\\\n",
      " ('Spec7(DUSTY)', 'Spec4(QUIESCENT)')     & 12.7 \\\\\n",
      " ('Spec7(DUSTY)', 'Spec5(QUIESCENT)')     & 12.6 \\\\\n",
      " ('Spec7(DUSTY)', 'Spec6(DUSTY)')         & 12.6 \\\\\n",
      " ('Spec7(DUSTY)', 'Spec8(STARBURST)')     & 12.7 \\\\\n",
      " ('Spec7(DUSTY)', 'Spec9(STARBURST)')     & 12.5 \\\\\n",
      " ('Spec8(STARBURST)', 'Spec0(PASSIVE)')   & 13.2 \\\\\n",
      " ('Spec8(STARBURST)', 'Spec1(PASSIVE)')   & 12.7 \\\\\n",
      " ('Spec8(STARBURST)', 'Spec2(POST)')      & 12.6 \\\\\n",
      " ('Spec8(STARBURST)', 'Spec3(POST)')      & 12.3 \\\\\n",
      " ('Spec8(STARBURST)', 'Spec4(QUIESCENT)') & 12.6 \\\\\n",
      " ('Spec8(STARBURST)', 'Spec5(QUIESCENT)') & 12.8 \\\\\n",
      " ('Spec8(STARBURST)', 'Spec6(DUSTY)')     & 12.7 \\\\\n",
      " ('Spec8(STARBURST)', 'Spec7(DUSTY)')     & 12.8 \\\\\n",
      " ('Spec8(STARBURST)', 'Spec9(STARBURST)') & 12.3 \\\\\n",
      " ('Spec9(STARBURST)', 'Spec0(PASSIVE)')   & 12.8 \\\\\n",
      " ('Spec9(STARBURST)', 'Spec1(PASSIVE)')   & 12.7 \\\\\n",
      " ('Spec9(STARBURST)', 'Spec2(POST)')      & 12.7 \\\\\n",
      " ('Spec9(STARBURST)', 'Spec3(POST)')      & 12.4 \\\\\n",
      " ('Spec9(STARBURST)', 'Spec4(QUIESCENT)') & 12.6 \\\\\n",
      " ('Spec9(STARBURST)', 'Spec5(QUIESCENT)') & 12.7 \\\\\n",
      " ('Spec9(STARBURST)', 'Spec6(DUSTY)')     & 12.6 \\\\\n",
      " ('Spec9(STARBURST)', 'Spec7(DUSTY)')     & 12.9 \\\\\n",
      " ('Spec9(STARBURST)', 'Spec8(STARBURST)') & 12.6 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lrr}\n",
      "\\hline\n",
      " ('Spec0(PASSIVE)', 'Spec1(PASSIVE)')     & 0.182721  & 0.021338   \\\\\n",
      " ('Spec0(PASSIVE)', 'Spec2(POST)')        & 0.321383  & 0.0182959  \\\\\n",
      " ('Spec0(PASSIVE)', 'Spec3(POST)')        & 0.387043  & 0.0220324  \\\\\n",
      " ('Spec0(PASSIVE)', 'Spec4(QUIESCENT)')   & 0.162915  & 0.0112234  \\\\\n",
      " ('Spec0(PASSIVE)', 'Spec5(QUIESCENT)')   & 0.113971  & 0.00809637 \\\\\n",
      " ('Spec0(PASSIVE)', 'Spec6(DUSTY)')       & 0.28127   & 0.0161764  \\\\\n",
      " ('Spec0(PASSIVE)', 'Spec7(DUSTY)')       & 0.179072  & 0.0136237  \\\\\n",
      " ('Spec0(PASSIVE)', 'Spec8(STARBURST)')   & 0.185304  & 0.0129536  \\\\\n",
      " ('Spec0(PASSIVE)', 'Spec9(STARBURST)')   & 0.511843  & 0.0235007  \\\\\n",
      " ('Spec1(PASSIVE)', 'Spec0(PASSIVE)')     & 0.182721  & 0.021338   \\\\\n",
      " ('Spec1(PASSIVE)', 'Spec2(POST)')        & 0.78843   & 0.0376969  \\\\\n",
      " ('Spec1(PASSIVE)', 'Spec3(POST)')        & 0.908113  & 0.0414415  \\\\\n",
      " ('Spec1(PASSIVE)', 'Spec4(QUIESCENT)')   & 0.495743  & 0.0292802  \\\\\n",
      " ('Spec1(PASSIVE)', 'Spec5(QUIESCENT)')   & 0.24401   & 0.02319    \\\\\n",
      " ('Spec1(PASSIVE)', 'Spec6(DUSTY)')       & 0.744014  & 0.035211   \\\\\n",
      " ('Spec1(PASSIVE)', 'Spec7(DUSTY)')       & 0.515172  & 0.032044   \\\\\n",
      " ('Spec1(PASSIVE)', 'Spec8(STARBURST)')   & 0.50313   & 0.0280925  \\\\\n",
      " ('Spec1(PASSIVE)', 'Spec9(STARBURST)')   & 0.918917  & 0.0426648  \\\\\n",
      " ('Spec2(POST)', 'Spec0(PASSIVE)')        & 0.321383  & 0.0182959  \\\\\n",
      " ('Spec2(POST)', 'Spec1(PASSIVE)')        & 0.78843   & 0.0376969  \\\\\n",
      " ('Spec2(POST)', 'Spec3(POST)')           & 0.0558055 & 0.00528615 \\\\\n",
      " ('Spec2(POST)', 'Spec4(QUIESCENT)')      & 0.101598  & 0.00977717 \\\\\n",
      " ('Spec2(POST)', 'Spec5(QUIESCENT)')      & 0.197355  & 0.0163367  \\\\\n",
      " ('Spec2(POST)', 'Spec6(DUSTY)')          & 0.0633104 & 0.00498081 \\\\\n",
      " ('Spec2(POST)', 'Spec7(DUSTY)')          & 0.113765  & 0.00834713 \\\\\n",
      " ('Spec2(POST)', 'Spec8(STARBURST)')      & 0.150805  & 0.0149335  \\\\\n",
      " ('Spec2(POST)', 'Spec9(STARBURST)')      & 0.0861233 & 0.00724292 \\\\\n",
      " ('Spec3(POST)', 'Spec0(PASSIVE)')        & 0.387043  & 0.0220324  \\\\\n",
      " ('Spec3(POST)', 'Spec1(PASSIVE)')        & 0.908113  & 0.0414415  \\\\\n",
      " ('Spec3(POST)', 'Spec2(POST)')           & 0.0558055 & 0.00528615 \\\\\n",
      " ('Spec3(POST)', 'Spec4(QUIESCENT)')      & 0.123593  & 0.0130934  \\\\\n",
      " ('Spec3(POST)', 'Spec5(QUIESCENT)')      & 0.259369  & 0.019851   \\\\\n",
      " ('Spec3(POST)', 'Spec6(DUSTY)')          & 0.0752626 & 0.00734954 \\\\\n",
      " ('Spec3(POST)', 'Spec7(DUSTY)')          & 0.138453  & 0.0114295  \\\\\n",
      " ('Spec3(POST)', 'Spec8(STARBURST)')      & 0.170836  & 0.0178361  \\\\\n",
      " ('Spec3(POST)', 'Spec9(STARBURST)')      & 0.0560549 & 0.00494024 \\\\\n",
      " ('Spec4(QUIESCENT)', 'Spec0(PASSIVE)')   & 0.162915  & 0.0112234  \\\\\n",
      " ('Spec4(QUIESCENT)', 'Spec1(PASSIVE)')   & 0.495743  & 0.0292802  \\\\\n",
      " ('Spec4(QUIESCENT)', 'Spec2(POST)')      & 0.101598  & 0.00977717 \\\\\n",
      " ('Spec4(QUIESCENT)', 'Spec3(POST)')      & 0.123593  & 0.0130934  \\\\\n",
      " ('Spec4(QUIESCENT)', 'Spec5(QUIESCENT)') & 0.0965622 & 0.00875204 \\\\\n",
      " ('Spec4(QUIESCENT)', 'Spec6(DUSTY)')     & 0.0709896 & 0.00747731 \\\\\n",
      " ('Spec4(QUIESCENT)', 'Spec7(DUSTY)')     & 0.0820099 & 0.00705025 \\\\\n",
      " ('Spec4(QUIESCENT)', 'Spec8(STARBURST)') & 0.0857223 & 0.0100373  \\\\\n",
      " ('Spec4(QUIESCENT)', 'Spec9(STARBURST)') & 0.230998  & 0.0145635  \\\\\n",
      " ('Spec5(QUIESCENT)', 'Spec0(PASSIVE)')   & 0.113971  & 0.00809637 \\\\\n",
      " ('Spec5(QUIESCENT)', 'Spec1(PASSIVE)')   & 0.24401   & 0.02319    \\\\\n",
      " ('Spec5(QUIESCENT)', 'Spec2(POST)')      & 0.197355  & 0.0163367  \\\\\n",
      " ('Spec5(QUIESCENT)', 'Spec3(POST)')      & 0.259369  & 0.019851   \\\\\n",
      " ('Spec5(QUIESCENT)', 'Spec4(QUIESCENT)') & 0.0965622 & 0.00875204 \\\\\n",
      " ('Spec5(QUIESCENT)', 'Spec6(DUSTY)')     & 0.163975  & 0.0141174  \\\\\n",
      " ('Spec5(QUIESCENT)', 'Spec7(DUSTY)')     & 0.122256  & 0.0116725  \\\\\n",
      " ('Spec5(QUIESCENT)', 'Spec8(STARBURST)') & 0.124071  & 0.0102334  \\\\\n",
      " ('Spec5(QUIESCENT)', 'Spec9(STARBURST)') & 0.375883  & 0.0211527  \\\\\n",
      " ('Spec6(DUSTY)', 'Spec0(PASSIVE)')       & 0.28127   & 0.0161764  \\\\\n",
      " ('Spec6(DUSTY)', 'Spec1(PASSIVE)')       & 0.744014  & 0.035211   \\\\\n",
      " ('Spec6(DUSTY)', 'Spec2(POST)')          & 0.0633104 & 0.00498081 \\\\\n",
      " ('Spec6(DUSTY)', 'Spec3(POST)')          & 0.0752626 & 0.00734954 \\\\\n",
      " ('Spec6(DUSTY)', 'Spec4(QUIESCENT)')     & 0.0709896 & 0.00747731 \\\\\n",
      " ('Spec6(DUSTY)', 'Spec5(QUIESCENT)')     & 0.163975  & 0.0141174  \\\\\n",
      " ('Spec6(DUSTY)', 'Spec7(DUSTY)')         & 0.0887329 & 0.00724382 \\\\\n",
      " ('Spec6(DUSTY)', 'Spec8(STARBURST)')     & 0.114095  & 0.0130768  \\\\\n",
      " ('Spec6(DUSTY)', 'Spec9(STARBURST)')     & 0.111962  & 0.00909596 \\\\\n",
      " ('Spec7(DUSTY)', 'Spec0(PASSIVE)')       & 0.179072  & 0.0136237  \\\\\n",
      " ('Spec7(DUSTY)', 'Spec1(PASSIVE)')       & 0.515172  & 0.032044   \\\\\n",
      " ('Spec7(DUSTY)', 'Spec2(POST)')          & 0.113765  & 0.00834713 \\\\\n",
      " ('Spec7(DUSTY)', 'Spec3(POST)')          & 0.138453  & 0.0114295  \\\\\n",
      " ('Spec7(DUSTY)', 'Spec4(QUIESCENT)')     & 0.0820099 & 0.00705025 \\\\\n",
      " ('Spec7(DUSTY)', 'Spec5(QUIESCENT)')     & 0.122256  & 0.0116725  \\\\\n",
      " ('Spec7(DUSTY)', 'Spec6(DUSTY)')         & 0.0887329 & 0.00724382 \\\\\n",
      " ('Spec7(DUSTY)', 'Spec8(STARBURST)')     & 0.10412   & 0.0119715  \\\\\n",
      " ('Spec7(DUSTY)', 'Spec9(STARBURST)')     & 0.192752  & 0.012832   \\\\\n",
      " ('Spec8(STARBURST)', 'Spec0(PASSIVE)')   & 0.185304  & 0.0129536  \\\\\n",
      " ('Spec8(STARBURST)', 'Spec1(PASSIVE)')   & 0.50313   & 0.0280925  \\\\\n",
      " ('Spec8(STARBURST)', 'Spec2(POST)')      & 0.150805  & 0.0149335  \\\\\n",
      " ('Spec8(STARBURST)', 'Spec3(POST)')      & 0.170836  & 0.0178361  \\\\\n",
      " ('Spec8(STARBURST)', 'Spec4(QUIESCENT)') & 0.0857223 & 0.0100373  \\\\\n",
      " ('Spec8(STARBURST)', 'Spec5(QUIESCENT)') & 0.124071  & 0.0102334  \\\\\n",
      " ('Spec8(STARBURST)', 'Spec6(DUSTY)')     & 0.114095  & 0.0130768  \\\\\n",
      " ('Spec8(STARBURST)', 'Spec7(DUSTY)')     & 0.10412   & 0.0119715  \\\\\n",
      " ('Spec8(STARBURST)', 'Spec9(STARBURST)') & 0.283123  & 0.0189807  \\\\\n",
      " ('Spec9(STARBURST)', 'Spec0(PASSIVE)')   & 0.511843  & 0.0235007  \\\\\n",
      " ('Spec9(STARBURST)', 'Spec1(PASSIVE)')   & 0.918917  & 0.0426648  \\\\\n",
      " ('Spec9(STARBURST)', 'Spec2(POST)')      & 0.0861233 & 0.00724292 \\\\\n",
      " ('Spec9(STARBURST)', 'Spec3(POST)')      & 0.0560549 & 0.00494024 \\\\\n",
      " ('Spec9(STARBURST)', 'Spec4(QUIESCENT)') & 0.230998  & 0.0145635  \\\\\n",
      " ('Spec9(STARBURST)', 'Spec5(QUIESCENT)') & 0.375883  & 0.0211527  \\\\\n",
      " ('Spec9(STARBURST)', 'Spec6(DUSTY)')     & 0.111962  & 0.00909596 \\\\\n",
      " ('Spec9(STARBURST)', 'Spec7(DUSTY)')     & 0.192752  & 0.012832   \\\\\n",
      " ('Spec9(STARBURST)', 'Spec8(STARBURST)') & 0.283123  & 0.0189807  \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# Print results for distances and computations times\n",
    "\n",
    "all_times_all = all_times\n",
    "distances_all = distances\n",
    "print(tabulate(all_times_all, tablefmt='latex'))\n",
    "print(tabulate(distances_all, tablefmt='latex'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import collections\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "\n",
    "from numpy import load\n",
    "from numpy import exp\n",
    "from numpy import sqrt\n",
    "from numpy import pi\n",
    "from numpy import array\n",
    "from numpy import log\n",
    "from numpy import where\n",
    "from numpy import zeros\n",
    "from numpy import mean\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "from postmanager.score import Score\n",
    "from premanager.listing import Listing\n",
    "\n",
    "from random import randint\n",
    "from premanager.extractor import Extractor\n",
    "from premanager.listing import GALAXIES_TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "n_neighbors = 5\n",
    "n_folds = 10\n",
    "sigma = 1\n",
    "\n",
    "parts = {}\n",
    "for galaxy in GALAXIES_TYPES:\n",
    "    parts[galaxy] = 0\n",
    "\n",
    "curves_list = []\n",
    "with open('outputs/index_file.txt', 'r') as index_file:\n",
    "    for line in index_file.readlines():\n",
    "        curves_list.append(eval(line.strip())[1:2][0])\n",
    "\n",
    "curves_types = []\n",
    "for curve_index in range(0,len(curves_list)):\n",
    "    curves_types.append(curves_list[curve_index][1])\n",
    "    parts[curves_list[curve_index][1]] += 1\n",
    "\n",
    "parts = {k: v/len(curves_list) for k, v in parts.items()}\n",
    "\n",
    "aux = load(\"outputs/corrected_matrix\")\n",
    "cost_matrix = aux + aux.T\n",
    "\n",
    "def my_distance(x, y):\n",
    "    x = int(x[0])\n",
    "    y = int(y[0])\n",
    "    return cost_matrix[x][y]\n",
    "\n",
    "def gauss(x, sigma):\n",
    "    return exp(-(x / sigma)**2 / 2) / (sqrt(2 * pi) * sigma)\n",
    "\n",
    "def gaussian_kernel(distances_list):\n",
    "      return array([gauss(distance, sigma) for distance in distances_list])\n",
    "\n",
    "scores = {'DUSTY': Score('DUSTY'),\n",
    "          'PASSIVE': Score('PASSIVE'),\n",
    "          'POST': Score('POST'),\n",
    "          'QUIESCENT': Score('QUIESCENT'),\n",
    "          'STARBURST': Score('STARBURST')}\n",
    "\n",
    "fscores_mean = []\n",
    "for k in range(1, n_neighbors + 1):\n",
    "    fscores = []\n",
    "#     print (\"-----------------------------------\")\n",
    "#     print(\"NUMBER OF NEIGHBORS CONSIDERED: \"+str(k))\n",
    "    knn = KNN(n_neighbors=k, algorithm='ball_tree', weights=gaussian_kernel,\n",
    "            metric='pyfunc', func=my_distance)\n",
    "    \n",
    "    big_conf_matrix = zeros([5, 5])\n",
    "\n",
    "    for train_set, test_set in Score.k_cross(len(curves_types), n_folds):\n",
    "\n",
    "        real_labels_train_set = [curves_types[i] for i in train_set]\n",
    "        real_labels_test_set = [curves_types[i] for i in test_set]\n",
    "\n",
    "        train_set = [[train_set[i]] for i in range(0,len(train_set))]\n",
    "        test_set = [[test_set[i]] for i in range(0,len(test_set))]\n",
    "\n",
    "        knn.fit(train_set, real_labels_train_set)\n",
    "\n",
    "        predicted_labels_test_set = knn.predict(test_set)\n",
    "\n",
    "        for i in range(0, len(real_labels_test_set)):\n",
    "            predicted_class = predicted_labels_test_set[i]\n",
    "            real_class = real_labels_test_set[i]\n",
    "            \n",
    "            pred_class_num = Extractor.get_file_class_number('asd', class_string=predicted_class)\n",
    "            real_class_num = Extractor.get_file_class_number('asd', class_string=real_class)\n",
    "\n",
    "            big_conf_matrix[real_class_num][pred_class_num] += 1\n",
    "            for c in GALAXIES_TYPES:\n",
    "                scores[c].update_confusion_matrix(predicted_class, real_class)\n",
    "\n",
    "    results = []\n",
    "    headers = []\n",
    "    print (\"\\n\")\n",
    "    for c in GALAXIES_TYPES:\n",
    "        ordered_scores = scores[c].get_results()\n",
    "        fscores.append(scores[c].compute_fscore())\n",
    "        ordered_scores = {k: str(round(v*100,2))+' %' for k, v in ordered_scores.items()}\n",
    "        ordered_scores = collections.OrderedDict(sorted(ordered_scores.items()))\n",
    "        elements_to_del = ['1_accuracy','2_MCC','4_specificity', '6_NPV', '7_fall_out', '8_FDR', '9_FNR']\n",
    "        for elem in elements_to_del:\n",
    "            del ordered_scores[elem]\n",
    "        results = [ordered_scores]\n",
    "\n",
    "#         print (c.upper())\n",
    "#         print (tabulate(results, headers=\"keys\", tablefmt=\"latex\"))\n",
    "#         print (\"\\n\")\n",
    "#         print (\"-----------------------------------\")\n",
    "\n",
    "    fscores_mean.append([k,str(round(mean(fscores)*100,2))+' %'])\n",
    "\n",
    "\n",
    "print(tabulate(fscores_mean, tablefmt='latex'))\n",
    "headers = [0,1,2,3,4]\n",
    "headers_class = []\n",
    "for i in headers:\n",
    "    hc = Extractor.get_class_string_from_number(i)\n",
    "    headers_class.append(hc)\n",
    "    \n",
    "print(tabulate(big_conf_matrix, headers=headers_class, tablefmt='latex'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset # We reset the namespace to avoid possible confusions between the two methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd method: Peaker + Hyper-Parameter Optimization + Filtering + Gaussian Fit + Decision Trees + Classification\n",
    "\n",
    "### Peaker\n",
    "Let $X=(x_1, x_2, ..., x_N)$ represent the relative radiation flux values of a given spectrum.\n",
    "The first three possible peaker score functions are the following:\n",
    "\n",
    "$$S_1(x_i, X, k) = \\frac{\\max\\{x_i-x_{i-1}, x_i-x_{i-2},..., x_i-x_{i-k}\\} + \\max\\{x_i-x_{i+1}, x_i-x_{i+2},..., x_i - x_{i+k}\\}}{2}$$\n",
    "\n",
    "$$S_2(x_i, X, k) = x_i - \\frac{(x_{i-1}+x_{i-2}+...+x_{i-k}) + (x_{i+1}+ x_{i+2}+...+ x_{i+k})}{2k}$$\n",
    "\n",
    "$$S_3(x_i, X, k) = \\frac{(x_i-x_{i-1}+ x_i-x_{i-2}+...+ x_i-x_{i-k}) + (x_i-x_{i+1}+ x_i-x_{i+2}+...+ x_i - x_{i+k})}{2k}$$\n",
    "\n",
    "For the peaker score function $S_4$ we introduce the concept of entropy.   \n",
    "We need to choose first a kernel between the Epanechnikov kernel $K_e$\n",
    "\n",
    "$$ K_e(x) =\n",
    "\\left\\{\n",
    "\t\\begin{array}{ll}\n",
    "\t\t\\frac{3}{4}(1-x^2)  & \\mbox{if } |x| < 1 \\\\\n",
    "        0 & \\mbox{otherwise}\n",
    "\t\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "and the Gauss kernel $K_g$\n",
    "$$K_g(x) = \\frac{1}{\\sqrt{2\\pi}}\\exp^{\\frac{-1}{2}x^2}$$\n",
    "\n",
    "Then, we define the estimate of the probability density at $x_i$ to be\n",
    "$$p_w(x_i) = \\frac{1}{N|x_i-x_{i+w}|}\\sum_{j=1}^NK\\big(\\frac{x_i-x_j}{|x_i-x_{i+w}|}\\big)$$\n",
    "We define the entropy of the sequence $X$ to be\n",
    "$$H_w(X) = \\sum_{i=1}^N\\big(-p_w(x_i)\\log(p_w(x_i))\\big)$$\n",
    "\n",
    "We call $N_-(x_i, X, k)$ and $N_+(x_i, X, k)$ the left and right neighbours of $x_i$. We also define $$N(x_i, X, k) = N_- \\cup N_+$$\n",
    "and $$N'(x_i, X, k) = N_- \\cup \\{x_i\\} \\cup N_+$$\n",
    "\n",
    "We can therefore define the $S_4$ score functions as follow:\n",
    "\n",
    "$$S_4(x_i, X, k, w) = H_w(N(x_i, X, k)) - H_w(N'(x_i, X, k))$$\n",
    "\n",
    "which in a way represents the variation in entropy when the potential peak $x_i$ is part of the series.\n",
    "\n",
    "Finally we define a fifth peak function $S_5$. This function is a little bit different from the others, since it doesn't consider a score for $x_i$, but rather evaluates how far from the local standard deviation it is. So if we call $\\mu$ and $\\sigma$ the experimental mean and standard deviation of the $2k$ points in $N(x_i, X, k)$, we say that $x_i$ is a peak if \n",
    "$$|x_i - \\mu| \\geq 3\\sigma$$\n",
    "\n",
    "The user is now invited to choose one of the five possible peak score functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from numpy import zeros\n",
    "\n",
    "from premanager.peaker import Peaker\n",
    "\n",
    "# Please uncomment the wanted peak function (just one choice)\n",
    "\n",
    "# peak_function_type = 1 # Default choice\n",
    "# peak_function_type = 2\n",
    "peak_function_type = 3\n",
    "# peak_function_type = 4\n",
    "# peak_function_type = 5\n",
    "# peak_function_type = 6\n",
    "\n",
    "left_cut_point = 0 # Minimum observed wavelength on which cut the spectrum\n",
    "right_cut_point = 9200 # Maximum observed wavelength on which cut the spectrum\n",
    "\n",
    "total_fscores = []\n",
    "big_conf_matrix = zeros([5, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Parameter Optimization\n",
    "Once the peak score function has been chosen by the user, we perform an automatic optimization of its parameters, basing ourselves on the training set. The search of those optimal parameter can be done in two ways: grid or random. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from premanager.listing import Listing\n",
    "from premanager.listing import GALAXIES_TYPES\n",
    "\n",
    "from postmanager.score import Score\n",
    "\n",
    "\n",
    "# Define train and test files\n",
    "all_files = []\n",
    "# all_files.extend(Listing.get_random_files('PASSIVE', 20))\n",
    "# for galaxy_type in GALAXIES_TYPES:\n",
    "#     if galaxy_type != 'PASSIVE':\n",
    "#         all_files.extend(Listing.get_all_files_type(galaxy_type))\n",
    "        \n",
    "# for galaxy_type in GALAXIES_TYPES:\n",
    "#     all_files.extend(Listing.get_random_files(galaxy_type, 14))\n",
    "\n",
    "all_files = Listing.get_all_file_names()\n",
    "\n",
    "# 20 random Passive (among 108), 21 Post, 23 Quiescent, 14 Dusty, 20 Starburst --> Total = 78 different files\n",
    "train_test_sets = Score.k_cross(len(all_files), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Obtaining train and test files\n",
    "train_set_aux = train_test_sets.__next__() # This step returns the next train and test files to be used\n",
    "train_files = [all_files[i] for i in train_set_aux[0]] \n",
    "test_files = [all_files[i] for i in train_set_aux[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from premanager.optimizer import Optimizer\n",
    "\n",
    "lambda_window = 10 # Window in which a peak is considered being correct (compared to the official list of peaks)\n",
    "\n",
    "my_opt = Optimizer(train_files, peak_function_type, left_cut_point, right_cut_point, lambda_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to choose between a grid search and a random search, for the optimal parameters for the given peak function.  \n",
    "Please uncomment the wanted option. This process may take long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# If grid search is chosen (default choice)\n",
    "from time import time\n",
    "\n",
    "param_min = [50] # list of the minimum value that each parameter can take; a value per parameter\n",
    "param_steps = [15] # list of the constant step between two values of each paramter; a value per parameter\n",
    "amount_points = [15] # list of the amount of points wanted for each parameter; a value per parameter\n",
    "\n",
    "start = time()\n",
    "optimal_params = my_opt.grid_search(param_min, param_steps, amount_points)\n",
    "end = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If random search is chosen\n",
    "# \"\"\"\n",
    "from time import time\n",
    "\n",
    "param_min = [10] # list of the minimum value that each parameter can take; a value per parameter\n",
    "param_max = [200] # list of the maximum value that each parameter can take; a value per parameter\n",
    "amount_points = [15] # list of the amount of points wanted for each parameter; a value per parameter\n",
    "\n",
    "start = time()\n",
    "optimal_params = my_opt.random_search(param_min, param_max, amount_points)\n",
    "end = time()\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Computation time = '+str(end-start)+' seconds.')\n",
    "print('Optimal parameters tuple: '+ str(optimal_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peakering: we search for the peaks on each spectrum\n",
    "Having the optimal parameters for the peak functions, we search for the peaks on all the spectra. The peaks are found according to the peak function, where we consider a point to be a peak if its score given by the score function escapes the values of the neighbourhood.  \n",
    "In other words, a point $x_i$ is considered a peak, using the score function $S$, if:\n",
    "$$S(x_i, X, k)-\\mu \\geq h*\\sigma$$\n",
    "where $\\mu$ and $\\sigma$ are the mean and standard deviation of $N(x_i, X, k)$, and $h$ is the threshold.  \n",
    "After finding the peaks, we filter them in two different ways: windows and curvature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Fit\n",
    "Once the peaks have been found, we adjust them to a Gaussian profile of the form $$y=A\\exp^{-(x-\\mu)^2/2\\sigma^2}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equivalent Width (EW) computation\n",
    "Once the gaussian fit has been done for each peak, we compute their equivalent width which is expressed as \n",
    "$$EW = \\int_{\\lambda_1}^{\\lambda_2} \\frac{x_c-y_{\\lambda}}{x_c}d\\lambda$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "optimal_params = (198,)\n",
    "from premanager.extractor import Extractor\n",
    "get_file_class_number = Extractor.get_file_class_number\n",
    "get_obs_values = Extractor.get_obs_values\n",
    "open_fits_file = Extractor.open_fits_file\n",
    "close_fits_file = Extractor.close_fits_file\n",
    "\n",
    "from postmanager.fit import Fit\n",
    "\n",
    "train_features = [] # We initialize the list with the training set features in the form of [(peak_obs_wave, EW), ...]\n",
    "train_labels = [] # We initialize the list with the training set labels in the form of [0, 0, 2, 3, ...]\n",
    "                  # (each number corresponds to a class)\n",
    "\n",
    "for spec_file_name in train_files:\n",
    "    spec_label = get_file_class_number(spec_file_name)\n",
    "    \n",
    "    spec_fits_file = open_fits_file(spec_file_name) # We open the corresponding fits file\n",
    "    x_obs, rad_flux = get_obs_values(spec_file_name, spec_fits_file, left_cut_point, right_cut_point)\n",
    "    \n",
    "    # 1. We find the peaks for spec_file\n",
    "    spec_peaker = Peaker(rad_flux) # One peaker per spectrum\n",
    "    spec_peaks = spec_peaker.get_peaks(peak_function_type, *optimal_params) # We store the peaks by their indices\n",
    "    \n",
    "    # 2. We fit the peaks to a Gaussian normal and compute the equivalent widths\n",
    "    fit_window = 40 # We define the fitting window in angstrom \n",
    "    spec_fitter = Fit(spec_fits_file, x_obs, rad_flux, spec_peaks, fit_window) # One fitter per spectrum\n",
    "    close_fits_file(spec_fits_file) # After this point we don't need the fits file anymore\n",
    "    spec_peaks_EW = spec_fitter.get_all_EW() # We compute all the EW - Each EW correspond to the peak in spec_peaks\n",
    "                                             # The returned list is of the form [(peak_obs_wavelength, peak_EW),...]\n",
    "    \n",
    "    # 3. We add the features of this spec_file to a training features list\n",
    "    train_features.append(spec_peaks_EW)    \n",
    "    train_labels.append(spec_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees: building decision trees with EW per range as feature\n",
    "Once the equivalent width have been computed, for each peak, we will build decision trees with EW per range of wavelength as feature.  \n",
    "Since we do not actually know the redshift of a test spectrum, we will build one decision tree for every possible redshift between the minimum and the maximum redshift of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from subprocess import check_call\n",
    "\n",
    "from numpy import arange\n",
    "from premanager.extractor import ALL_SELECTED_LINES\n",
    "from postmanager.decision_trees import DecisionTree\n",
    "\n",
    "from premanager.listing import GALAXIES_TYPES\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "# Get min and max redshift\n",
    "min_red, max_red = Extractor.get_min_max_redshift()\n",
    "\n",
    "# Define redshift step\n",
    "step_red = 0.01\n",
    "\n",
    "amount_trees = (max_red - min_red)/step_red\n",
    "print(\"A total of \" + str(int(amount_trees)) + \" decision trees.\")\n",
    "\n",
    "all_decision_trees = []\n",
    "# One decision tree per possible redshift\n",
    "for j in arange(min_red, max_red, step_red):\n",
    "    min_r = j\n",
    "    max_r = j + step_red\n",
    "    \n",
    "    start = time()\n",
    "    current_decision_tree = DecisionTree(min_r, max_r, ALL_SELECTED_LINES, train_features, train_labels)\n",
    "    current_decision_tree.fit_tree()\n",
    "    end = time()\n",
    "    all_decision_trees.append(current_decision_tree)\n",
    "\n",
    "    \n",
    "#     tree_name = 'tree'+str(j)\n",
    "#     tree.export_graphviz(current_decision_tree.tree, out_file='outputs/'+tree_name+'.dot',\n",
    "#                          class_names=GALAXIES_TYPES, label='none', impurity=False)\n",
    "\n",
    "#     check_call(['dot','-Tpng','/Users/tomasyany/Code/memoria/outputs/'+tree_name+'.dot',\n",
    "#                 '-o','/Users/tomasyany/Code/memoria/outputs/'+tree_name+'.png'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification: most voted class among the decision trees\n",
    "Once all the decision trees have been computed, we choose the class as the most voted among all the decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from premanager.listing import Listing\n",
    "\n",
    "from premanager.extractor import Extractor\n",
    "get_file_class_number = Extractor.get_file_class_number\n",
    "get_obs_values = Extractor.get_obs_values\n",
    "open_fits_file = Extractor.open_fits_file\n",
    "close_fits_file = Extractor.close_fits_file\n",
    "\n",
    "from postmanager.fit import Fit\n",
    "\n",
    "test_features = [] # We initialize the list with the training set features in the form of [(peak_obs_wave, EW), ...]\n",
    "test_labels = [] # We initialize the list with the training set labels in the form of [0, 0, 2, 3, ...]\n",
    "                  # (each number corresponds to a class)\n",
    "\n",
    "for spec_file_name in test_files:\n",
    "    spec_label = get_file_class_number(spec_file_name)\n",
    "    \n",
    "    spec_fits_file = open_fits_file(spec_file_name) # We open the corresponding fits file\n",
    "    x_obs, rad_flux = get_obs_values(spec_file_name, spec_fits_file, left_cut_point, right_cut_point)\n",
    "    \n",
    "    # 1. We find the peaks for spec_file\n",
    "    spec_peaker = Peaker(rad_flux) # One peaker per spectrum\n",
    "    spec_peaks = spec_peaker.get_peaks(peak_function_type, *optimal_params) # We store the peaks by their indices\n",
    "    \n",
    "    # 2. We fit the peaks to a Gaussian normal and compute the equivalent widths\n",
    "    spec_fitter = Fit(spec_fits_file, x_obs, rad_flux, spec_peaks, fit_window) # One fitter per spectrum\n",
    "    close_fits_file(spec_fits_file) # After this point we don't need the fits file anymore\n",
    "    spec_peaks_EW = spec_fitter.get_all_EW() # We compute all the EW - Each EW correspond to the peak in spec_peaks\n",
    "                                             # The returned list is of the form [(peak_obs_wavelength, peak_EW),...]\n",
    "    \n",
    "    # 3. We add the features of this spec_file to a training features list\n",
    "    test_features.append(spec_peaks_EW)    \n",
    "    test_labels.append(spec_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from numpy import zeros\n",
    "from numpy import vstack\n",
    "from numpy import mean\n",
    "\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "from postmanager.score import Score\n",
    "\n",
    "scores = {'DUSTY': Score('DUSTY'),\n",
    "          'PASSIVE': Score('PASSIVE'),\n",
    "          'POST': Score('POST'),\n",
    "          'QUIESCENT': Score('QUIESCENT'),\n",
    "          'STARBURST': Score('STARBURST')}\n",
    "\n",
    "amount_test_spec = len(test_files)\n",
    "all_predicted_classes = zeros((0, amount_test_spec), int)\n",
    "\n",
    "for decision_tree in all_decision_trees:\n",
    "    predicted_classes = decision_tree.predict_test_classes(test_features) # Predicted classes for the current DT\n",
    "    all_predicted_classes = vstack([all_predicted_classes, predicted_classes]) # Add row to all the predicted classes\n",
    "\n",
    "all_spec_voted_labels = []\n",
    "for spec_index, spec_file_name in enumerate(test_files):\n",
    "    fscores = []\n",
    "    \n",
    "    spec_predicted_labels = all_predicted_classes[:, spec_index]\n",
    "    spec_real_label = Extractor.get_file_class_string(spec_file_name)\n",
    "\n",
    "    num_label = Extractor.get_file_class_number(spec_file_name)\n",
    "\n",
    "    # Get most voted class among all the decision trees\n",
    "    votes = Counter(spec_predicted_labels).most_common()\n",
    "    if len(votes) > 1:\n",
    "        spec_voted_label = votes[1][0]\n",
    "    else:\n",
    "        spec_voted_label = votes[0][0]\n",
    "\n",
    "    voted_label = Extractor.get_class_string_from_number(spec_voted_label)\n",
    "    \n",
    "    big_conf_matrix[num_label][spec_voted_label] += 1\n",
    "    for c in GALAXIES_TYPES:\n",
    "        scores[c].update_confusion_matrix(voted_label, spec_real_label)\n",
    "    \n",
    "    all_spec_voted_labels.append(spec_voted_label)\n",
    "    \n",
    "results = []\n",
    "headers = []\n",
    "fscores = []\n",
    "for c in GALAXIES_TYPES:\n",
    "    ordered_scores = scores[c].get_results()\n",
    "    fscores.append(scores[c].compute_fscore())\n",
    "\n",
    "print(fscores)\n",
    "print(mean(fscores))\n",
    "total_fscores.append(fscores)\n",
    "\n",
    "headers = [0,1,2,3,4]\n",
    "headers_class = []\n",
    "for i in headers:\n",
    "    hc = Extractor.get_class_string_from_number(i)\n",
    "    headers_class.append(hc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(tabulate(total_fscores, tablefmt='latex'))\n",
    "print(tabulate(big_conf_matrix, headers=headers_class, tablefmt='latex'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
